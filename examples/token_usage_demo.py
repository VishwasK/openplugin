"""Demonstrate token usage differences in web search plugin."""

import asyncio
import os
from openplugin.utils import WebSearcher
from examples.web_search_app import WebSearchApp


def demonstrate_token_usage():
    """Show which methods use tokens and which don't."""
    
    print("=" * 70)
    print("TOKEN USAGE IN WEB SEARCH PLUGIN")
    print("=" * 70)
    
    searcher = WebSearcher()
    query = "Python async programming"
    
    print("\n1Ô∏è‚É£  SIMPLE SEARCH (NO LLM, NO TOKENS)")
    print("-" * 70)
    print("Method: searcher.search() or searcher.search_and_format()")
    print("Token Usage: 0 ‚úÖ")
    print("\nExample:")
    results = searcher.search(query, max_results=3)
    print(f"   Found {len(results)} results")
    print(f"   First result: {results[0]['title'][:50]}...")
    print("   ‚úÖ Zero tokens used!")
    
    print("\n" + "=" * 70)
    print("2Ô∏è‚É£  SEARCH WITH PLUGIN (USES LLM, TOKENS COUNT)")
    print("-" * 70)
    print("Method: app.search()")
    print("Token Usage: ~1200-1400 tokens ‚ö†Ô∏è")
    print("\nWhat counts as tokens:")
    print("   ‚úÖ Your query: ~10 tokens")
    print("   ‚úÖ Search results (all snippets): ~1000 tokens")
    print("   ‚úÖ System prompt: ~200 tokens")
    print("   ‚úÖ LLM response: ~200 tokens")
    print("\n‚ö†Ô∏è  Search results ARE included in prompt = INPUT tokens!")
    
    print("\n" + "=" * 70)
    print("3Ô∏è‚É£  SEARCH AND SUMMARIZE (MORE TOKENS)")
    print("-" * 70)
    print("Method: app.search_and_summarize()")
    print("Token Usage: ~1600-2800 tokens ‚ö†Ô∏è")
    print("\nWhat counts as tokens:")
    print("   ‚úÖ Your question: ~20 tokens")
    print("   ‚úÖ Search results: ~1000-2000 tokens")
    print("   ‚úÖ System prompt: ~300 tokens")
    print("   ‚úÖ Summary response: ~400-500 tokens")
    
    print("\n" + "=" * 70)
    print("COST ESTIMATION (OpenAI GPT-4)")
    print("-" * 70)
    print("Simple Search:        $0.00 (no LLM)")
    print("Search (3 results):   ~$0.03 per search")
    print("Search (5 results):   ~$0.05 per search")
    print("Summarize (5 results): ~$0.06 per search")
    print("\nüí° Tip: Use GPT-3.5-turbo for 20x cheaper (~$0.001 per search)")
    
    print("\n" + "=" * 70)
    print("HOW TO MINIMIZE TOKENS")
    print("-" * 70)
    print("1. Use simple_search() when you just need results")
    print("2. Reduce num_results (2-3 instead of 5-10)")
    print("3. Use GPT-3.5-turbo instead of GPT-4")
    print("4. Cache results to avoid re-searching")
    print("5. Extract only titles/URLs, not full snippets")


async def compare_methods():
    """Compare different search methods side by side."""
    
    if not os.getenv("OPENAI_API_KEY"):
        print("\n‚ö†Ô∏è  OPENAI_API_KEY not set. Skipping LLM examples.")
        print("   Set it to see token usage with LLM methods.")
        return
    
    app = WebSearchApp(openai_api_key=os.getenv("OPENAI_API_KEY"))
    query = "Python async programming best practices"
    
    print("\n" + "=" * 70)
    print("COMPARISON: Different Search Methods")
    print("=" * 70)
    
    # Method 1: No LLM
    print("\nüìä Method 1: Simple Search (NO TOKENS)")
    print("-" * 70)
    start = asyncio.get_event_loop().time()
    simple_results = app.simple_search(query, num_results=3)
    elapsed = asyncio.get_event_loop().time() - start
    print(f"‚úÖ Completed in {elapsed:.2f}s")
    print(f"‚úÖ Token usage: 0")
    print(f"‚úÖ Results: {len(app.get_raw_results(query, 3))} found")
    
    # Method 2: With LLM formatting
    print("\nüìä Method 2: Search with LLM Formatting (TOKENS USED)")
    print("-" * 70)
    start = asyncio.get_event_loop().time()
    llm_results = await app.search(query, num_results=3)
    elapsed = asyncio.get_event_loop().time() - start
    print(f"‚úÖ Completed in {elapsed:.2f}s")
    print(f"‚ö†Ô∏è  Token usage: ~800-1200 tokens")
    print(f"‚úÖ Results formatted by LLM")
    
    # Method 3: Summarize
    print("\nüìä Method 3: Search and Summarize (MORE TOKENS)")
    print("-" * 70)
    start = asyncio.get_event_loop().time()
    summary_results = await app.search_and_summarize(query, num_results=3)
    elapsed = asyncio.get_event_loop().time() - start
    print(f"‚úÖ Completed in {elapsed:.2f}s")
    print(f"‚ö†Ô∏è  Token usage: ~1200-1600 tokens")
    print(f"‚úÖ Summary generated")
    
    await app.shutdown()


if __name__ == "__main__":
    demonstrate_token_usage()
    
    print("\n" + "=" * 70)
    print("Would you like to see a live comparison? (y/n)")
    if input().strip().lower() == 'y':
        asyncio.run(compare_methods())
